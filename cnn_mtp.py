# -*- coding: utf-8 -*-
"""CNN_MTP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C1c6JnbW-ulLMy5UAA_5R_nEmdF1XT7s
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2
import numpy as np
import pandas as pd
import os

img = image.load_img("/content/k0000.png")
img1 = image.load_img("/content/k0010.png")
img2 = image.load_img("/content/k0020.png")
img3 = image.load_img("/content/k0030.png")
img4 = image.load_img("/content/k0040.png")
img5 = image.load_img("/content/k0050.png")
img6 = image.load_img("/content/k0060.png")
img7 = image.load_img("/content/k0070.png")
img8 = image.load_img("/content/k0080.png")
img9 = image.load_img("/content/k0090.png")
img10 = image.load_img("/content/k0100.png")
plt.imshow(img)

plt.imshow(img1)

plt.imshow(img7)

plt.imshow(img10)



array = cv2.imread("/content/k0000.png")
array

from sklearn.model_selection import train_test_split

cv2.imread("/content/k0000.png").shape

train = ImageDataGenerator(rescale=1/255)
validation = ImageDataGenerator(rescale=1/255)

import pandas as pd
df = pd.read_csv('/content/dataframe_fracture_stress.csv')
df

pd.set_option("display.max_rows", 100)
pd.set_option("display.max_rows", None)

df['label'] = pd.factorize(df.defect_conc)[0]

shuffled = df.sample(frac=1).reset_index()
df1 = pd.DataFrame(shuffled)
df2 = df1.sort_values('defect_conc', ascending = True)
df2

df_final = df.iloc[:,0:5]
df_final

corr = df_final.corr()

import seaborn as sns
sns.heatmap(corr, annot = True)



df_4 = df.head(24)

df_5 = df.iloc[25:54, :]
df_5



plt.plot(df_4['defect_conc'], df_4['Fracture stress'])
plt.plot(df_5['defect_conc'], df_5['Fracture stress'])

X = df_final.drop(columns = 'Fracture stress', axis = 1)
Y = df_final['Fracture stress']

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 0)

import numpy as np
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
array = np.asarray(Y_train)
scaled_data = array.reshape(-1,1)
Y_train = scaler.fit_transform(scaled_data)

X_train = np.asarray(X_train)
X_test = np.asarray(X_test)

from xgboost import XGBRegressor

model = XGBRegressor()
model.fit(X_train, Y_train, verbose=False)



from sklearn.metrics import accuracy_score
prediction = model.predict(X_train)

prediction = model.predict(X_test)

from sklearn.metrics import mean_squared_error
print("Mean squared Error : " + str(mean_squared_error(prediction, Y_test)))

from sklearn.metrics import mean_absolute_error
print("Mean Absolute Error : " + str(mean_absolute_error(prediction, Y_test)))

import seaborn as sns
sns.distplot(prediction)

df_final

for fracture_stress in df_final:
  fracture_stress = df_final['Fracture stress']/ 0.4

fracture_stress

from sklearn import linear_model
from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, RepeatedKFold
lr = linear_model.LinearRegression()

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)
kfold = KFold(n_splits = 5, shuffle = True, random_state = 42 )
lr.fit(X_train, Y_train)

lr = linear_model.LinearRegression()
cv = RepeatedKFold(n_splits = 5, n_repeats = 3, random_state = 42)
scores = cross_val_score(lr, X, Y, cv = cv)
r2_mean = scores.mean()
print("%0.4f accuracy with a standard deviation of %0.4f" % (r2_mean, scores.std()))
print(scores)

yhat_lr = cross_val_predict(lr, X, Y, cv = kfold)

f, ax = plt.subplots(figsize=(8, 8))
label_mlr = "$R^2$ = %.2f" % r2_mean
plt.plot(Y, yhat_lr, 'o', label=label_mlr, color = "magenta")
plt.ylabel(r"$σ_{predicted}$")
plt.xlabel(r"$σ_{actual}$")
plt.legend()
plt.xlim([2.5, 10])
plt.ylim([2.5, 10])
plt.plot([2.5, 10], [2.5, 10], 'k--')
plt.show()

test_dataframe = pd.read_csv('/content/test_file_borophene.csv')

test_dataframe

submission=pd.DataFrame({'defect conc.':test_dataframe['defect conc.'],
                        'Fracture stress':yhat_lr.astype('float')})


submission

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df1 = pd.read_csv('/content/test_file_borophene.csv')
df1

import matplotlib.pyplot as plt
plt.figure(figsize=(10,8))
plt.plot(df1['defect conc.'], df1['Fracture stress'])

X = df1.drop(columns = 'Fracture stress', axis = 1)
Y = df1['Fracture stress']

from sklearn import linear_model
from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, RepeatedKFold
lr = linear_model.LinearRegression()

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)
kfold = KFold(n_splits = 2, shuffle = True, random_state = 42 )
lr.fit(X_train, Y_train)

lr = linear_model.LinearRegression()
cv = RepeatedKFold(n_splits = 2, n_repeats = 3, random_state = 42)
scores = cross_val_score(lr, X, Y, cv = cv)
r2_mean = scores.mean()
print("%0.4f accuracy with a standard deviation of %0.4f" % (r2_mean, scores.std()))
print(scores)

X_test

yhat_lr = cross_val_predict(lr, X, Y, cv = kfold)

f, ax = plt.subplots(figsize=(8, 8))
label_mlr = "$R^2$ = %.2f" % r2_mean
plt.plot(Y, yhat_lr, 'o', label=label_mlr, color = "magenta")
plt.ylabel(r"$σ_{predicted}$")
plt.xlabel(r"$σ_{actual}$)")
plt.legend()
plt.xlim([2.5, 10])
plt.ylim([2.5, 10])
plt.plot([2.5, 10], [2.5, 10], 'k--')
plt.show()

lr.fit(X_train, Y_train)

Y_pred = lr.predict(X_test)

Y_pred

X_pred = lr.predict(X_train)
X_pred

Y_test

X_test

x_test = X_test.iloc[:,0]
x_test

Y_pred

Y_test

fig, ax = plt.subplots(figsize=(12, 6))
ax.plot(x_test, Y_pred)
ax.plot(x_test,Y_test)
plt.xlim([1,10])
plt.show()

df2 = pd.read_excel('/content/otput_file_500.xlsx')
df2

plt.plot(df2['defect conc.'], df2['Fracture stress'])

X = df2.drop(columns = 'Fracture stress', axis = 1)
Y = df2['Fracture stress']

from sklearn import linear_model
from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, RepeatedKFold
lr = linear_model.LinearRegression()

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)
kfold = KFold(n_splits = 2, shuffle = True, random_state = 42 )
lr.fit(X_train, Y_train)

lr = linear_model.LinearRegression()
cv = RepeatedKFold(n_splits = 2, n_repeats = 3, random_state = 42)
scores = cross_val_score(lr, X, Y, cv = cv)
r2_mean = scores.mean()
print("%0.4f accuracy with a standard deviation of %0.4f" % (r2_mean, scores.std()))
print(scores)

yhat_lr = cross_val_predict(lr, X, Y, cv = kfold)

f, ax = plt.subplots(figsize=(8, 8))
label_mlr = "$R^2$ = %.2f" % r2_mean
plt.plot(Y, yhat_lr, 'o', label=label_mlr, color = "magenta")
plt.ylabel(r"$σ_{predicted}$")
plt.xlabel(r"$σ_{actual}$")
plt.legend()
plt.xlim([2.5, 10])
plt.ylim([2.5, 10])
plt.plot([2.5, 10], [2.5, 10], 'k--')
plt.show()

lr.fit(X_train, Y_train)

Y_pred = lr.predict(X_test)
Y_pred

Y_test

df3 = pd.read_excel('/content/output_700.xlsx')
df3

df4 = pd.read_excel('/content/output_900.xlsx')
df4

df_merged = pd.concat([df1, df2, df3, df4], ignore_index = True, sort = False)
df_merged

X = df_merged.drop(columns = 'Fracture stress', axis = 1)
Y = df_merged['Fracture stress']

from sklearn import linear_model
from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, RepeatedKFold
lr = linear_model.LinearRegression()

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)
kfold = KFold(n_splits = 2, shuffle = True, random_state = 42 )
lr.fit(X_train, Y_train)

lr = linear_model.LinearRegression()
cv = RepeatedKFold(n_splits = 2, n_repeats = 3, random_state = 42)
scores = cross_val_score(lr, X, Y, cv = cv)
r2_mean = scores.mean()
print("%0.4f accuracy with a standard deviation of %0.4f" % (r2_mean, scores.std()))
print(scores)

yhat_lr = cross_val_predict(lr, X, Y, cv = kfold)

f, ax = plt.subplots(figsize=(8, 8))
label_mlr = "$R^2$ = %.2f" % r2_mean
plt.plot(Y, yhat_lr, 'o', label=label_mlr, color = "magenta")
plt.ylabel(r"$σ_{predicted}$")
plt.xlabel(r"$σ_{actual}$")
plt.legend()
plt.xlim([2.5, 10])
plt.ylim([2.5, 10])
plt.plot([2.5, 10], [2.5, 10], 'k--')
plt.show()

X_test

Y_test

y_test = Y_test.sort_values(ascending=False)

lr.fit(X_train, Y_train)

Y_pred = lr.predict(X_test)
Y_pred

Y_test

predicted_values = pd.DataFrame(Y_pred)
y_pred = predicted_values.sort_values(by = 0,ascending = False)
y_pred

X

plt.plot(X_test['defect conc.'], y_test)
plt.plot(X_test['defect conc.'], y_pred)

! git clone "https://github.com/mohitrrane/yolov5"
! cd yolov5
! pip install -r yolov5/requirements.txt
! pip install -r yolov5/requirements.txt

from google.colab import files
import os
import zipfile
import io

import torch
from IPython.display import Image  # for displaying images
import os
import random
import shutil
from sklearn.model_selection import train_test_split
import xml.etree.ElementTree as ET
from xml.dom import minidom
from tqdm import tqdm
from PIL import Image, ImageDraw
import numpy as np
import matplotlib.pyplot as plt

random.seed(108)

uploaded = files.upload()
os.listdir('.')

zf = zipfile.ZipFile(io.BytesIO(uploaded['train.zip']), "r")
zf.extractall()
os.listdir('.')

images = [os.path.join('defective/images', x) for x in os.listdir('defective/images')]
annotations = [os.path.join('defective/annotations', x) for x in os.listdir('defective/annotations') if x[-3:] == "txt"]

images.sort()
annotations.sort()

# Split the dataset into train-valid-test splits
train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.1, random_state = 1)
val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)

import matplotlib.pyplot as plt
plt.scatter(df1['defect conc.'], df1['Fracture stress'], label = 'Temp = 300K')
plt.scatter(df2['defect conc.'], df2['Fracture stress'], label = 'Temp = 500K')
plt.scatter(df3['defect conc.'], df3['Fracture stress'], label = 'Temp = 700K')
plt.scatter(df4['defect conc.'], df4['Fracture stress'], label = 'Temp = 900K')
plt.xlabel('Vacancy Concentration')
plt.ylabel('Fracture stress(N/m)')
plt.legend(frameon = False)

import seaborn as sns
sns.pairplot(df_merged)

df_merged

plt.scatter(df1['Temperature'], df1['Fracture stress'], label = 'Temp = 300K')
plt.scatter(df2['Temperature'], df2['Fracture stress'], label = 'Temp = 500K')
plt.scatter(df3['Temperature'], df3['Fracture stress'], label = 'Temp = 700K')
plt.scatter(df4['Temperature'], df4['Fracture stress'], label = 'Temp = 900K')
plt.xlabel('Temperature')
plt.ylabel('Fracture stress(N/m)')
plt.legend(frameon = False)

pip install dataset

# Commented out IPython magic to ensure Python compatibility.
import time
import math
import random

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2


from sklearn.metrics import confusion_matrix
from datetime import timedelta

# %matplotlib inline

filter_size1 = 3
num_filters1 = 32

# Convolutional Layer 2.
filter_size2 = 3
num_filters2 = 32

# Convolutional Layer 3.
filter_size3 = 3
num_filters3 = 64

# Fully-connected layer.
fc_size = 128             # Number of neurons in fully-connected layer.

# Number of color channels for the images: 1 channel for gray-scale.
num_channels = 3

# image dimensions (only squares for now)
img_size = 128

# Size of image when flattened to a single dimension
img_size_flat = img_size * img_size * num_channels

# Tuple with height and width of images used to reshape arrays.
img_shape = (img_size, img_size)

# class info
classes = ['0.001', '0.002', '0.003', '0.004', '0.005', '0006', '0.007', '0.008', '0.009', '0.01', '0.02', '0.03', '0.04']
num_classes = len(classes)

# batch size
batch_size = 32

# validation split
validation_size = .16

# how long to wait after validation loss stops improving before terminating training
early_stopping = None  # use None if you don't want to implement early stoping

train_path = '/content/train.zip'
test_path = '/content/test.zip'

!unzip /content/train.zip
!unzip /content/test.zip

train_path

from keras.layers import Dense, Flatten
from keras.models import Model
from keras.applications.inception_v3 import InceptionV3, preprocess_input
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import load_img
from tensorflow.keras.utils import img_to_array
import keras

base_model = InceptionV3(input_shape=(256,256,3), include_top = False)

for layer in base_model.layers:
  layer.trainable = False

X = Flatten()(base_model.output)
X = Dense(units = len(classes), activation = 'sigmoid')(X)
model = Model(base_model.input, X)
model.compile(optimizer= 'adam', loss = keras.losses.binary_crossentropy, metrics = ['accuracy'])
model.summary()

train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)
train_data = train_datagen.flow_from_directory(directory ='/content/train' , target_size=(256,256), batch_size = 10)

train_data.class_indices

t_img, label =train_data.next()
t_img.shape

import matplotlib.pyplot as plt
def plotImage(img_arr, label):
  for idx, img in enumerate(img_arr):
    if idx <= 10:
      plt.figure(figsize=(5,5))
      plt.imshow(img)
      plt.title(img.shape)
      plt.axis = False
      plt.show()

plotImage(t_img, label)

from keras.callbacks import ModelCheckpoint, EarlyStopping
mc = ModelCheckpoint(filepath= "./best_model.h5",
                     monitor = 'accuracy',
                     verbose = 1,
                     save_best_only = True )



es = EarlyStopping(monitor = "accuracy", min_delta = 0.01,
                   patience = 5, verbose = 1)
cb = [mc,es]

his = model.fit(train_data, epochs = 30, callbacks =cb)

from keras.models import load_model
model = load_model("/content/best_model.h5")

h = his.history
h.keys()

plt.plot(h['loss'], 'go--', label = 'loss')
plt.plot(h['accuracy'], 'go--', c = 'red', label = 'accuracy')
plt.title("loss vs accuracy")
plt.legend()
plt.show()

import numpy as np
path = "/content/test/10010_0.04.png"
img = load_img(path, target_size=(256,256))
i = img_to_array(img)
i = preprocess_input(i)
input_arr = np.array([i])
input_arr.shape

pred = np.argmax(model.predict(input_arr))

if pred == 0:
  print('This image is of 0.1% vacancy concentration')
elif pred == 1:
  print('This image is of 0.2% vacancy concentration')
elif pred == 2:
  print('Ths image is of 0.3% vacancy concentration')
elif pred == 3:
  print('This image is of 0.4% vacancy concentration')
elif pred == 4:
  print('This image is of 0.5% vacancy concentration')
elif pred == 5:
  print('This image is of 0.6% vacancy concentration')
elif pred == 6:
  print('This image is of 0.7% vacancy concentration')
elif pred == 7:
  print('This image is of 0.8% vacancy concentration')
elif pred == 8:
  print('This image is of 0.9% vacancy concentration')
elif pred == 9:
  print('This image is of 1% vacancy concentration')
elif pred == 10:
  print('This image is of 2% vacancy concentration')
elif pred == 11:
  print('This image is of 3% vacancy concentration')
elif pred == 12:
  print('This image is of 4% vacancy concentration')
else:
  print('Sorry the image is wrong')


plt.imshow(input_arr[0])
plt.title("input image")
plt.show()

import matplotlib.pyplot as plt
plt.plot(df1[''])